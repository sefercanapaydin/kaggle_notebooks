{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e0670c",
   "metadata": {
    "papermill": {
     "duration": 0.015672,
     "end_time": "2023-03-28T21:09:45.534612",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.518940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3b68c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.563679Z",
     "iopub.status.busy": "2023-03-28T21:09:45.562877Z",
     "iopub.status.idle": "2023-03-28T21:09:45.574699Z",
     "shell.execute_reply": "2023-03-28T21:09:45.573721Z"
    },
    "papermill": {
     "duration": 0.028791,
     "end_time": "2023-03-28T21:09:45.577792",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.549001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_df(dataframe, head=5):\n",
    "    print(\"##################### Shape #####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"##################### Types #####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"##################### Head #####################\")\n",
    "    print(dataframe.head(head))\n",
    "    print(\"##################### Tail #####################\")\n",
    "    print(dataframe.tail(head))\n",
    "    print(\"##################### NA #####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"##################### Quantiles #####################\")\n",
    "    print(dataframe.describe([0, 0.05, 0.50, 0.95, 0.99, 1]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626b65a",
   "metadata": {
    "papermill": {
     "duration": 0.013942,
     "end_time": "2023-03-28T21:09:45.611171",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.597229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Outliers\n",
    "0.01 ve 0.99 verisetine göre değişkenlik göstermesi beklenir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e037366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.636967Z",
     "iopub.status.busy": "2023-03-28T21:09:45.636563Z",
     "iopub.status.idle": "2023-03-28T21:09:45.643255Z",
     "shell.execute_reply": "2023-03-28T21:09:45.641881Z"
    },
    "papermill": {
     "duration": 0.022907,
     "end_time": "2023-03-28T21:09:45.645516",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.622609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def outlier_thresholds(dataframe, variable):\n",
    "    quartile1 = dataframe[variable].quantile(0.01)\n",
    "    quartile3 = dataframe[variable].quantile(0.99)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    # dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354e8268",
   "metadata": {
    "papermill": {
     "duration": 0.010983,
     "end_time": "2023-03-28T21:09:45.668368",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.657385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1d4dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.693281Z",
     "iopub.status.busy": "2023-03-28T21:09:45.692859Z",
     "iopub.status.idle": "2023-03-28T21:09:45.703684Z",
     "shell.execute_reply": "2023-03-28T21:09:45.702513Z"
    },
    "papermill": {
     "duration": 0.026231,
     "end_time": "2023-03-28T21:09:45.706164",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.679933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grab_col_names(dataframe, cat_th=10,  car_th=20):\n",
    "    \"\"\"\n",
    "    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: dataframe\n",
    "        değişken isimleri alınmak istenen dataframe'dir.\n",
    "    cat_th: int, float\n",
    "        numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n",
    "    car_th: int, float\n",
    "        kategorik fakat kardinal değişkenler için sınıf eşik değeri\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cat_cols: list\n",
    "        Kategorik değişken listesi\n",
    "    num_cols: list\n",
    "        Numerik değişken listesi\n",
    "    cat_but_car: list\n",
    "        Kategorik görünümlü kardinal değişken listesi\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "    cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
    "    num_but_cat cat_cols'un içerisinde.\n",
    "\n",
    "    \"\"\"\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in df.columns if str(df[col].dtypes) in [\"category\", \"object\", \"bool\"]]\n",
    "\n",
    "    num_but_cat = [col for col in df.columns if df[col].nunique() < 10 and df[col].dtypes in [\"int\", \"float\"]]\n",
    "\n",
    "    cat_but_car = [col for col in df.columns if\n",
    "                   df[col].nunique() > 20 and str(df[col].dtypes) in [\"category\", \"object\"]]\n",
    "\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    num_cols = [col for col in df.columns if df[col].dtypes in [\"int\", \"float\"]]\n",
    "    num_cols = [col for col in num_cols if col not in cat_cols]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "\n",
    "    return cat_cols, num_cols, cat_but_car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1741e09",
   "metadata": {
    "papermill": {
     "duration": 0.010895,
     "end_time": "2023-03-28T21:09:45.728249",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.717354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alttaki fonksiyon kategorik değişkenlerin ağırlıklarını ve yüzdesel oranlarını gösteriyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b268c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.754406Z",
     "iopub.status.busy": "2023-03-28T21:09:45.752875Z",
     "iopub.status.idle": "2023-03-28T21:09:45.760797Z",
     "shell.execute_reply": "2023-03-28T21:09:45.759739Z"
    },
    "papermill": {
     "duration": 0.023587,
     "end_time": "2023-03-28T21:09:45.763373",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.739786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cat_summary(dataframe, col_name, plot=False):\n",
    "    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "    print(\"##########################################\")\n",
    "\n",
    "    if plot:\n",
    "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "        plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99643296",
   "metadata": {
    "papermill": {
     "duration": 0.010829,
     "end_time": "2023-03-28T21:09:45.785614",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.774785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alttaki fonksiyon numerik değerlerin describe değerlerini gösteriyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96cef7be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.810463Z",
     "iopub.status.busy": "2023-03-28T21:09:45.810029Z",
     "iopub.status.idle": "2023-03-28T21:09:45.816820Z",
     "shell.execute_reply": "2023-03-28T21:09:45.815839Z"
    },
    "papermill": {
     "duration": 0.021665,
     "end_time": "2023-03-28T21:09:45.818827",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.797162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def num_summary(dataframe, numerical_col, plot=False):\n",
    "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "    print(dataframe[numerical_col].describe(quantiles).T)\n",
    "\n",
    "    if plot:\n",
    "        dataframe[numerical_col].hist()\n",
    "        plt.xlabel(numerical_col)\n",
    "        plt.title(numerical_col)\n",
    "        plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f8e392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.843915Z",
     "iopub.status.busy": "2023-03-28T21:09:45.843165Z",
     "iopub.status.idle": "2023-03-28T21:09:45.848457Z",
     "shell.execute_reply": "2023-03-28T21:09:45.847184Z"
    },
    "papermill": {
     "duration": 0.02096,
     "end_time": "2023-03-28T21:09:45.851169",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.830209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_summary_with_num(dataframe, target, numerical_col):\n",
    "    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e364a5f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.876379Z",
     "iopub.status.busy": "2023-03-28T21:09:45.875944Z",
     "iopub.status.idle": "2023-03-28T21:09:45.882510Z",
     "shell.execute_reply": "2023-03-28T21:09:45.881319Z"
    },
    "papermill": {
     "duration": 0.022414,
     "end_time": "2023-03-28T21:09:45.884782",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.862368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_summary_with_cat(dataframe, target, categorical_col):\n",
    "    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54813e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T20:31:15.588470Z",
     "iopub.status.busy": "2023-03-28T20:31:15.587991Z",
     "iopub.status.idle": "2023-03-28T20:31:15.599706Z",
     "shell.execute_reply": "2023-03-28T20:31:15.598035Z",
     "shell.execute_reply.started": "2023-03-28T20:31:15.588422Z"
    },
    "papermill": {
     "duration": 0.01087,
     "end_time": "2023-03-28T21:09:45.906924",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.896054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Aşağıdaki fonksiyon yüksek korelasyona sahip olan değişkenlerden birini çıkarten liste oluşturur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2880fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.931936Z",
     "iopub.status.busy": "2023-03-28T21:09:45.930812Z",
     "iopub.status.idle": "2023-03-28T21:09:45.939657Z",
     "shell.execute_reply": "2023-03-28T21:09:45.938585Z"
    },
    "papermill": {
     "duration": 0.025905,
     "end_time": "2023-03-28T21:09:45.944018",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.918113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def high_correlated_cols(dataframe, plot=False, corr_th=0.90):\n",
    "    corr = dataframe.corr()\n",
    "    cor_matrix = corr.abs()\n",
    "    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))\n",
    "    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n",
    "    if plot:\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        sns.set(rc={'figure.figsize': (15, 15)})\n",
    "        sns.heatmap(corr, cmap=\"RdBu\")\n",
    "        plt.show()\n",
    "    return drop_list\n",
    "\n",
    "# high_correlated_cols(df)\n",
    "# drop_list = high_correlated_cols(df, plot=True)\n",
    "# df.drop(drop_list, axis=1)\n",
    "# high_correlated_cols(df.drop(drop_list, axis=1), plot=True)\n",
    "# sonrasında bu adımlar yapılarak dataframeden yuksek korelasyonlu değişken çıkartılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93961d3b",
   "metadata": {
    "papermill": {
     "duration": 0.012411,
     "end_time": "2023-03-28T21:09:45.971676",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.959265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc87bcd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:45.998836Z",
     "iopub.status.busy": "2023-03-28T21:09:45.997573Z",
     "iopub.status.idle": "2023-03-28T21:09:46.014787Z",
     "shell.execute_reply": "2023-03-28T21:09:46.013572Z"
    },
    "papermill": {
     "duration": 0.033134,
     "end_time": "2023-03-28T21:09:46.017480",
     "exception": false,
     "start_time": "2023-03-28T21:09:45.984346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rfm(dataframe, csv=False):\n",
    "\n",
    "    # VERIYI HAZIRLAMA Aşağıdaki veri hazırlama kısmı örnekte yapılan dataframe uygundur başka örneklerde değişebilir. \n",
    "    dataframe[\"TotalPrice\"] = dataframe[\"Quantity\"] * dataframe[\"Price\"]\n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n",
    "\n",
    "    # RFM METRIKLERININ HESAPLANMASI bu kısım örneğe özeldir eldeki dataframe e göre değişebilir\n",
    "    today_date = dt.datetime(2011, 12, 11) \n",
    "    rfm = dataframe.groupby('Customer ID').agg({'InvoiceDate': lambda date: (today_date - date.max()).days,\n",
    "                                                'Invoice': lambda num: num.nunique(),\n",
    "                                                \"TotalPrice\": lambda price: price.sum()})\n",
    "    rfm.columns = ['recency', 'frequency', \"monetary\"]\n",
    "    rfm = rfm[(rfm['monetary'] > 0)]\n",
    "\n",
    "    # RFM SKORLARININ HESAPLANMASI\n",
    "    rfm[\"recency_score\"] = pd.qcut(rfm['recency'], 5, labels=[5, 4, 3, 2, 1])\n",
    "    rfm[\"frequency_score\"] = pd.qcut(rfm[\"frequency\"].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n",
    "    rfm[\"monetary_score\"] = pd.qcut(rfm['monetary'], 5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "    # cltv_df skorları kategorik değere dönüştürülüp df'e eklendi\n",
    "    rfm[\"RFM_SCORE\"] = (rfm['recency_score'].astype(str) +\n",
    "                        rfm['frequency_score'].astype(str))\n",
    "\n",
    "\n",
    "    # SEGMENTLERIN ISIMLENDIRILMESI\n",
    "    seg_map = {\n",
    "        r'[1-2][1-2]': 'hibernating',\n",
    "        r'[1-2][3-4]': 'at_risk',\n",
    "        r'[1-2]5': 'cant_loose',\n",
    "        r'3[1-2]': 'about_to_sleep',\n",
    "        r'33': 'need_attention',\n",
    "        r'[3-4][4-5]': 'loyal_customers',\n",
    "        r'41': 'promising',\n",
    "        r'51': 'new_customers',\n",
    "        r'[4-5][2-3]': 'potential_loyalists',\n",
    "        r'5[4-5]': 'champions'\n",
    "    }\n",
    "\n",
    "    rfm['segment'] = rfm['RFM_SCORE'].replace(seg_map, regex=True)\n",
    "    rfm = rfm[[\"recency\", \"frequency\", \"monetary\", \"segment\"]]\n",
    "    rfm.index = rfm.index.astype(int)\n",
    "\n",
    "    if csv:\n",
    "        rfm.to_csv(\"rfm.csv\")\n",
    "\n",
    "    return rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6221c9",
   "metadata": {
    "papermill": {
     "duration": 0.011377,
     "end_time": "2023-03-28T21:09:46.042827",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.031450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CLTV\n",
    "*  1. Veri Hazırlama\n",
    "*  2. Average Order Value (average_order_value = total_price / total_transaction)\n",
    "*  3. Purchase Frequency (total_transaction / total_number_of_customers)\n",
    "*  4. Repeat Rate & Churn Rate (birden fazla alışveriş yapan müşteri sayısı / tüm müşteriler)\n",
    "*  5. Profit Margin (profit_margin =  total_price * 0.10)\n",
    "*  6. Customer Value (customer_value = average_order_value * purchase_frequency)\n",
    "*  7. Customer Lifetime Value (CLTV = (customer_value / churn_rate) x profit_margin)\n",
    "*  8. Segmentlerin Oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4ac23a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.067549Z",
     "iopub.status.busy": "2023-03-28T21:09:46.066766Z",
     "iopub.status.idle": "2023-03-28T21:09:46.077402Z",
     "shell.execute_reply": "2023-03-28T21:09:46.076169Z"
    },
    "papermill": {
     "duration": 0.026387,
     "end_time": "2023-03-28T21:09:46.080435",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.054048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cltv_c(dataframe, profit=0.10):\n",
    "\n",
    "    # Veriyi hazırlama\n",
    "    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n",
    "    dataframe = dataframe[(dataframe['Quantity'] > 0)]\n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe[\"TotalPrice\"] = dataframe[\"Quantity\"] * dataframe[\"Price\"]\n",
    "    cltv_c = dataframe.groupby('Customer ID').agg({'Invoice': lambda x: x.nunique(),\n",
    "                                                   'Quantity': lambda x: x.sum(),\n",
    "                                                   'TotalPrice': lambda x: x.sum()})\n",
    "    cltv_c.columns = ['total_transaction', 'total_unit', 'total_price']\n",
    "    # avg_order_value\n",
    "    cltv_c['avg_order_value'] = cltv_c['total_price'] / cltv_c['total_transaction']\n",
    "    # purchase_frequency\n",
    "    cltv_c[\"purchase_frequency\"] = cltv_c['total_transaction'] / cltv_c.shape[0]\n",
    "    # repeat rate & churn rate\n",
    "    repeat_rate = cltv_c[cltv_c.total_transaction > 1].shape[0] / cltv_c.shape[0]\n",
    "    churn_rate = 1 - repeat_rate\n",
    "    # profit_margin\n",
    "    cltv_c['profit_margin'] = cltv_c['total_price'] * profit\n",
    "    # Customer Value\n",
    "    cltv_c['customer_value'] = (cltv_c['avg_order_value'] * cltv_c[\"purchase_frequency\"])\n",
    "    # Customer Lifetime Value\n",
    "    cltv_c['cltv'] = (cltv_c['customer_value'] / churn_rate) * cltv_c['profit_margin']\n",
    "    # Segment\n",
    "    cltv_c[\"segment\"] = pd.qcut(cltv_c[\"cltv\"], 4, labels=[\"D\", \"C\", \"B\", \"A\"])\n",
    "\n",
    "    return cltv_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a681ca9",
   "metadata": {
    "papermill": {
     "duration": 0.010956,
     "end_time": "2023-03-28T21:09:46.102844",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.091888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CLTV-Prediction\n",
    "*  1. Verinin Hazırlanması (Data Preperation)\n",
    "*  2. BG-NBD Modeli ile Expected Number of Transaction\n",
    "*  3. Gamma-Gamma Modeli ile Expected Average Profit\n",
    "*  4. BG-NBD ve Gamma-Gamma Modeli ile CLTV'nin Hesaplanması\n",
    "*  5. CLTV'ye Göre Segmentlerin Oluşturulması\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59810df5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.129614Z",
     "iopub.status.busy": "2023-03-28T21:09:46.129176Z",
     "iopub.status.idle": "2023-03-28T21:09:46.146433Z",
     "shell.execute_reply": "2023-03-28T21:09:46.144971Z"
    },
    "papermill": {
     "duration": 0.033192,
     "end_time": "2023-03-28T21:09:46.149025",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.115833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cltv_p(dataframe, month=3):\n",
    "    # !pip install lifetimes\n",
    "    import datetime as dt\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lifetimes import BetaGeoFitter\n",
    "    from lifetimes import GammaGammaFitter\n",
    "    from lifetimes.plotting import plot_period_transactions\n",
    "    # 1. Veri Ön İşleme\n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n",
    "    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n",
    "    dataframe = dataframe[dataframe[\"Price\"] > 0]\n",
    "    replace_with_thresholds(dataframe, \"Quantity\")\n",
    "    replace_with_thresholds(dataframe, \"Price\")\n",
    "    dataframe[\"TotalPrice\"] = dataframe[\"Quantity\"] * dataframe[\"Price\"]\n",
    "    today_date = dt.datetime(2011, 12, 11)\n",
    "\n",
    "    cltv_df = dataframe.groupby('Customer ID').agg(\n",
    "        {'InvoiceDate': [lambda InvoiceDate: (InvoiceDate.max() - InvoiceDate.min()).days,\n",
    "                         lambda InvoiceDate: (today_date - InvoiceDate.min()).days],\n",
    "         'Invoice': lambda Invoice: Invoice.nunique(),\n",
    "         'TotalPrice': lambda TotalPrice: TotalPrice.sum()})\n",
    "\n",
    "    cltv_df.columns = cltv_df.columns.droplevel(0)\n",
    "    cltv_df.columns = ['recency', 'T', 'frequency', 'monetary']\n",
    "    cltv_df[\"monetary\"] = cltv_df[\"monetary\"] / cltv_df[\"frequency\"]\n",
    "    cltv_df = cltv_df[(cltv_df['frequency'] > 1)]\n",
    "    cltv_df[\"recency\"] = cltv_df[\"recency\"] / 7\n",
    "    cltv_df[\"T\"] = cltv_df[\"T\"] / 7\n",
    "\n",
    "    # 2. BG-NBD Modelinin Kurulması\n",
    "    bgf = BetaGeoFitter(penalizer_coef=0.001)\n",
    "    bgf.fit(cltv_df['frequency'],\n",
    "            cltv_df['recency'],\n",
    "            cltv_df['T'])\n",
    "\n",
    "    cltv_df[\"expected_purc_1_week\"] = bgf.predict(1,\n",
    "                                                  cltv_df['frequency'],\n",
    "                                                  cltv_df['recency'],\n",
    "                                                  cltv_df['T'])\n",
    "\n",
    "    cltv_df[\"expected_purc_1_month\"] = bgf.predict(4,\n",
    "                                                   cltv_df['frequency'],\n",
    "                                                   cltv_df['recency'],\n",
    "                                                   cltv_df['T'])\n",
    "\n",
    "    cltv_df[\"expected_purc_3_month\"] = bgf.predict(12,\n",
    "                                                   cltv_df['frequency'],\n",
    "                                                   cltv_df['recency'],\n",
    "                                                   cltv_df['T'])\n",
    "\n",
    "    # 3. GAMMA-GAMMA Modelinin Kurulması\n",
    "    ggf = GammaGammaFitter(penalizer_coef=0.01)\n",
    "    ggf.fit(cltv_df['frequency'], cltv_df['monetary'])\n",
    "    cltv_df[\"expected_average_profit\"] = ggf.conditional_expected_average_profit(cltv_df['frequency'],\n",
    "                                                                                 cltv_df['monetary'])\n",
    "\n",
    "    # 4. BG-NBD ve GG modeli ile CLTV'nin hesaplanması.\n",
    "    cltv = ggf.customer_lifetime_value(bgf,\n",
    "                                       cltv_df['frequency'],\n",
    "                                       cltv_df['recency'],\n",
    "                                       cltv_df['T'],\n",
    "                                       cltv_df['monetary'],\n",
    "                                       time=month,  # 3 aylık\n",
    "                                       freq=\"W\",  # T'nin frekans bilgisi.\n",
    "                                       discount_rate=0.01)\n",
    "\n",
    "    cltv = cltv.reset_index()\n",
    "    cltv_final = cltv_df.merge(cltv, on=\"Customer ID\", how=\"left\")\n",
    "    cltv_final[\"segment\"] = pd.qcut(cltv_final[\"clv\"], 4, labels=[\"D\", \"C\", \"B\", \"A\"])\n",
    "\n",
    "    return cltv_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a71d0",
   "metadata": {
    "papermill": {
     "duration": 0.011528,
     "end_time": "2023-03-28T21:09:46.171863",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.160335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Rating\n",
    "* Average\n",
    "* Time-Based Weighted Average\n",
    "* User-Based Weighted Average\n",
    "* Weighted Rating\n",
    "* Bayesian Average Rating Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a8caaae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.196803Z",
     "iopub.status.busy": "2023-03-28T21:09:46.195984Z",
     "iopub.status.idle": "2023-03-28T21:09:46.203672Z",
     "shell.execute_reply": "2023-03-28T21:09:46.202503Z"
    },
    "papermill": {
     "duration": 0.022857,
     "end_time": "2023-03-28T21:09:46.206015",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.183158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_based_weighted_average(dataframe, w1=28, w2=26, w3=24, w4=22):\n",
    "    return dataframe.loc[df[\"days\"] <= 30, \"Rating\"].mean() * w1 / 100 + \\\n",
    "           dataframe.loc[(dataframe[\"days\"] > 30) & (dataframe[\"days\"] <= 90), \"Rating\"].mean() * w2 / 100 + \\\n",
    "           dataframe.loc[(dataframe[\"days\"] > 90) & (dataframe[\"days\"] <= 180), \"Rating\"].mean() * w3 / 100 + \\\n",
    "           dataframe.loc[(dataframe[\"days\"] > 180), \"Rating\"].mean() * w4 / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ba19fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.230509Z",
     "iopub.status.busy": "2023-03-28T21:09:46.230122Z",
     "iopub.status.idle": "2023-03-28T21:09:46.237333Z",
     "shell.execute_reply": "2023-03-28T21:09:46.236017Z"
    },
    "papermill": {
     "duration": 0.022584,
     "end_time": "2023-03-28T21:09:46.239796",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.217212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def user_based_weighted_average(dataframe, w1=22, w2=24, w3=26, w4=28):\n",
    "    return dataframe.loc[dataframe[\"Progress\"] <= 10, \"Rating\"].mean() * w1 / 100 + \\\n",
    "           dataframe.loc[(dataframe[\"Progress\"] > 10) & (dataframe[\"Progress\"] <= 45), \"Rating\"].mean() * w2 / 100 + \\\n",
    "           dataframe.loc[(dataframe[\"Progress\"] > 45) & (dataframe[\"Progress\"] <= 75), \"Rating\"].mean() * w3 / 100 + \\\n",
    "           dataframe.loc[(dataframe[\"Progress\"] > 75), \"Rating\"].mean() * w4 / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a594e063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.264361Z",
     "iopub.status.busy": "2023-03-28T21:09:46.263718Z",
     "iopub.status.idle": "2023-03-28T21:09:46.269349Z",
     "shell.execute_reply": "2023-03-28T21:09:46.268298Z"
    },
    "papermill": {
     "duration": 0.021031,
     "end_time": "2023-03-28T21:09:46.271916",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.250885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def course_weighted_rating(dataframe, time_w=50, user_w=50):\n",
    "    return time_based_weighted_average(dataframe) * time_w/100 + user_based_weighted_average(dataframe)*user_w/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df237cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.297029Z",
     "iopub.status.busy": "2023-03-28T21:09:46.296602Z",
     "iopub.status.idle": "2023-03-28T21:09:46.304399Z",
     "shell.execute_reply": "2023-03-28T21:09:46.302992Z"
    },
    "papermill": {
     "duration": 0.023809,
     "end_time": "2023-03-28T21:09:46.307020",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.283211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bayesian_average_rating(n, confidence=0.95):\n",
    "    if sum(n) == 0:\n",
    "        return 0\n",
    "    K = len(n)\n",
    "    z = st.norm.ppf(1 - (1 - confidence) / 2)\n",
    "    N = sum(n)\n",
    "    first_part = 0.0\n",
    "    second_part = 0.0\n",
    "    for k, n_k in enumerate(n):\n",
    "        first_part += (k + 1) * (n[k] + 1) / (N + K)\n",
    "        second_part += (k + 1) * (k + 1) * (n[k] + 1) / (N + K)\n",
    "    score = first_part - z * math.sqrt((second_part - first_part * first_part) / (N + K + 1))\n",
    "    return score\n",
    "\n",
    "# df[\"bar_score\"] = df.apply(lambda x: bayesian_average_rating(x[[\"1_point\",\n",
    "#                                                                 \"2_point\",\n",
    "#                                                                 \"3_point\",\n",
    "#                                                                 \"4_point\",\n",
    "#                                                                 \"5_point\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49485408",
   "metadata": {
    "papermill": {
     "duration": 0.010923,
     "end_time": "2023-03-28T21:09:46.329168",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.318245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sorting\n",
    "* Sorting by Rating\n",
    "* Sorting by Comment Count or Purchase Count\n",
    "* Sorting by Rating, Comment and Purchase\n",
    "* Sorting by Bayesian Average Rating Score (Sorting Products with 5 Star Rated) (yeni ürünlerin pazarda öne çıkabilmesine yarıyor) cunku çok sayıdakı puan alan urunlerın 5 yıldızlı dagılımı ınceler ve daha az sayıdakı yorumluları potansıyel gelebılecegı yerı tahmınler\n",
    "* Hybrid Sorting: BAR Score + Diğer Faktorler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e22a2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.353956Z",
     "iopub.status.busy": "2023-03-28T21:09:46.353269Z",
     "iopub.status.idle": "2023-03-28T21:09:46.360763Z",
     "shell.execute_reply": "2023-03-28T21:09:46.359456Z"
    },
    "papermill": {
     "duration": 0.022922,
     "end_time": "2023-03-28T21:09:46.363294",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.340372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_sorting_score(dataframe, w1=32, w2=26, w3=42):\n",
    "    \n",
    "    df[\"purchase_count_scaled\"] = MinMaxScaler(feature_range=(1, 5)). \\\n",
    "    fit(df[[\"purchase_count\"]]). \\\n",
    "    transform(df[[\"purchase_count\"]])\n",
    "\n",
    "    df[\"comment_count_scaled\"] = MinMaxScaler(feature_range=(1, 5)). \\\n",
    "    fit(df[[\"commment_count\"]]). \\\n",
    "    transform(df[[\"commment_count\"]])\n",
    "\n",
    "    return (dataframe[\"comment_count_scaled\"] * w1 / 100 +\n",
    "            dataframe[\"purchase_count_scaled\"] * w2 / 100 +\n",
    "            dataframe[\"rating\"] * w3 / 100)\n",
    "\n",
    "# df[\"weighted_sorting_score\"] = weighted_sorting_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8784a10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.388502Z",
     "iopub.status.busy": "2023-03-28T21:09:46.388110Z",
     "iopub.status.idle": "2023-03-28T21:09:46.394526Z",
     "shell.execute_reply": "2023-03-28T21:09:46.393205Z"
    },
    "papermill": {
     "duration": 0.022627,
     "end_time": "2023-03-28T21:09:46.397245",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.374618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hybrid_sorting_score(dataframe, bar_w=60, wss_w=40):\n",
    "    bar_score = dataframe.apply(lambda x: bayesian_average_rating(x[[\"1_point\",\n",
    "                                                                     \"2_point\",\n",
    "                                                                     \"3_point\",\n",
    "                                                                     \"4_point\",\n",
    "                                                                     \"5_point\"]]), axis=1)\n",
    "    wss_score = weighted_sorting_score(dataframe)\n",
    "\n",
    "    return bar_score*bar_w/100 + wss_score*wss_w/100\n",
    "\n",
    "\n",
    "# df[\"hybrid_sorting_score\"] = hybrid_sorting_score(df)\n",
    "\n",
    "# df.sort_values(\"hybrid_sorting_score\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0601a3ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.421663Z",
     "iopub.status.busy": "2023-03-28T21:09:46.421220Z",
     "iopub.status.idle": "2023-03-28T21:09:46.426308Z",
     "shell.execute_reply": "2023-03-28T21:09:46.425115Z"
    },
    "papermill": {
     "duration": 0.020239,
     "end_time": "2023-03-28T21:09:46.428683",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.408444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vote_average * vote_count hızlı yakşalım için ayrı basit bir yöntem\n",
    "########################\n",
    "\n",
    "# df[\"average_count_score\"] = df[\"vote_average\"] * df[\"vote_count_score\"]\n",
    "\n",
    "# df.sort_values(\"average_count_score\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbf98a",
   "metadata": {
    "papermill": {
     "duration": 0.011,
     "end_time": "2023-03-28T21:09:46.450946",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.439946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMDB Eski sıralama yöntemi\n",
    "\n",
    "* r = vote average\n",
    "* v = vote count\n",
    "* M = minimum votes required to be listed in the Top 250\n",
    "* C = the mean vote across the whole report (currently 7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e21edbda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.475867Z",
     "iopub.status.busy": "2023-03-28T21:09:46.474940Z",
     "iopub.status.idle": "2023-03-28T21:09:46.481356Z",
     "shell.execute_reply": "2023-03-28T21:09:46.479877Z"
    },
    "papermill": {
     "duration": 0.02181,
     "end_time": "2023-03-28T21:09:46.484067",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.462257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# M = 2500\n",
    "# C = df['vote_average'].mean()\n",
    "\n",
    "def weighted_rating(r, v, M, C):\n",
    "    return (v / (v + M) * r) + (M / (v + M) * C)\n",
    "\n",
    "# df[\"weighted_rating\"] = weighted_rating(df[\"vote_average\"],\n",
    "#                                         df[\"vote_count\"], M, C)\n",
    "# df.sort_values(\"average_count_score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41718a72",
   "metadata": {
    "papermill": {
     "duration": 0.011038,
     "end_time": "2023-03-28T21:09:46.506773",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.495735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Aşağıdaki fonksiyonda zor olan kısım çağırılma şekilleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e029f35e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.531842Z",
     "iopub.status.busy": "2023-03-28T21:09:46.530776Z",
     "iopub.status.idle": "2023-03-28T21:09:46.539214Z",
     "shell.execute_reply": "2023-03-28T21:09:46.538261Z"
    },
    "papermill": {
     "duration": 0.023564,
     "end_time": "2023-03-28T21:09:46.541587",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.518023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bayesian_average_rating(n, confidence=0.95):\n",
    "    if sum(n) == 0:\n",
    "        return 0\n",
    "    K = len(n)\n",
    "    z = st.norm.ppf(1 - (1 - confidence) / 2)\n",
    "    N = sum(n)\n",
    "    first_part = 0.0\n",
    "    second_part = 0.0\n",
    "    for k, n_k in enumerate(n):\n",
    "        first_part += (k + 1) * (n[k] + 1) / (N + K)\n",
    "        second_part += (k + 1) * (k + 1) * (n[k] + 1) / (N + K)\n",
    "    score = first_part - z * math.sqrt((second_part - first_part * first_part) / (N + K + 1))\n",
    "    return score\n",
    "\n",
    "# df[\"bar_score\"] = df.apply(lambda x: bayesian_average_rating(x[[\"one\", \"two\", \"three\", \"four\", \"five\",\n",
    "#                                                                 \"six\", \"seven\", \"eight\", \"nine\", \"ten\"]]), axis=1)\n",
    "# df.sort_values(\"bar_score\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31baf395",
   "metadata": {
    "papermill": {
     "duration": 0.010884,
     "end_time": "2023-03-28T21:09:46.563687",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.552803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sorting Reviews (Wilson Lower Bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d748505b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.588008Z",
     "iopub.status.busy": "2023-03-28T21:09:46.587599Z",
     "iopub.status.idle": "2023-03-28T21:09:46.596284Z",
     "shell.execute_reply": "2023-03-28T21:09:46.594863Z"
    },
    "papermill": {
     "duration": 0.024229,
     "end_time": "2023-03-28T21:09:46.598947",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.574718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wilson_lower_bound(up, down, confidence=0.95):\n",
    "    import math\n",
    "    import scipy.stats as st\n",
    "    \"\"\"\n",
    "    Wilson Lower Bound Score hesapla\n",
    "\n",
    "    - Bernoulli parametresi p için hesaplanacak güven aralığının alt sınırı WLB skoru olarak kabul edilir.\n",
    "    - Hesaplanacak skor ürün sıralaması için kullanılır.\n",
    "    - Not:\n",
    "    Eğer skorlar 1-5 arasıdaysa 1-3 negatif, 4-5 pozitif olarak işaretlenir ve bernoulli'ye uygun hale getirilebilir.\n",
    "    Bu beraberinde bazı problemleri de getirir. Bu sebeple bayesian average rating yapmak gerekir.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    up: int\n",
    "        up count\n",
    "    down: int\n",
    "        down count\n",
    "    confidence: float\n",
    "        confidence\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wilson score: float\n",
    "\n",
    "    \"\"\"\n",
    "    n = up + down\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    z = st.norm.ppf(1 - (1 - confidence) / 2)\n",
    "    phat = 1.0 * up / n\n",
    "    return (phat + z * z / (2 * n) - z * math.sqrt((phat * (1 - phat) + z * z / (4 * n)) / n)) / (1 + z * z / n)\n",
    "\n",
    "\n",
    "# wilson_lower_bound\n",
    "# comments[\"wilson_lower_bound\"] = comments.apply(lambda x: wilson_lower_bound(x[\"up\"], x[\"down\"]), axis=1) çağırılma şekli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d1a61",
   "metadata": {
    "papermill": {
     "duration": 0.010988,
     "end_time": "2023-03-28T21:09:46.621498",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.610510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A/B Testing\n",
    "* 1. Hipotezleri Kur\n",
    "* 2. Varsayım Kontrolü\n",
    "*  - 1. Normallik Varsayımı\n",
    "*  - 2. Varyans Homojenliği\n",
    "* Hipotezin Uygulanması\n",
    "* - 1. Varsayımlar sağlanıyorsa bağımsız iki örneklem t testi (parametrik test)\n",
    "* - 2. Varsayımlar sağlanmıyorsa mannwhitneyu testi (non-parametrik test)\n",
    "* 4. p-value değerine göre sonuçları yorumla\n",
    "Not:\n",
    "* Normallik sağlanmıyorsa direk 2 numara. Varyans homojenliği sağlanmıyorsa 1 numaraya arguman girilir.\n",
    "* Normallik incelemesi öncesi aykırı değer incelemesi ve düzeltmesi yapmak faydalı olabilir.\n",
    "\n",
    "\n",
    "*  p-value < ise 0.05 'ten HO RED.\n",
    "*  p-value < değilse 0.05 H0 REDDEDILEMEZ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f32743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.646017Z",
     "iopub.status.busy": "2023-03-28T21:09:46.645583Z",
     "iopub.status.idle": "2023-03-28T21:09:46.659336Z",
     "shell.execute_reply": "2023-03-28T21:09:46.658125Z"
    },
    "papermill": {
     "duration": 0.029402,
     "end_time": "2023-03-28T21:09:46.662152",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.632750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A/B Testing Function - Quick Solution\n",
    "# ab[\"version\"] = np.where(ab.version == \"gate_30\", \"A\", \"B\")\n",
    "\n",
    "def AB_Test(dataframe, group, target):\n",
    "    \n",
    "    # Packages\n",
    "    from scipy.stats import shapiro\n",
    "    import scipy.stats as stats\n",
    "    \n",
    "    # Split A/B\n",
    "    groupA = dataframe[dataframe[group] == \"A\"][target]\n",
    "    groupB = dataframe[dataframe[group] == \"B\"][target]\n",
    "    \n",
    "    # Assumption: Normality\n",
    "    ntA = shapiro(groupA)[1] < 0.05\n",
    "    ntB = shapiro(groupB)[1] < 0.05\n",
    "    # H0: Distribution is Normal! - False\n",
    "    # H1: Distribution is not Normal! - True\n",
    "    \n",
    "    if (ntA == False) & (ntB == False): # \"H0: Normal Distribution\"\n",
    "        # Parametric Test\n",
    "        # Assumption: Homogeneity of variances\n",
    "        leveneTest = stats.levene(groupA, groupB)[1] < 0.05\n",
    "        # H0: Homogeneity: False\n",
    "        # H1: Heterogeneous: True\n",
    "        \n",
    "        if leveneTest == False:\n",
    "            # Homogeneity\n",
    "            ttest = stats.ttest_ind(groupA, groupB, equal_var=True)[1]\n",
    "            # H0: M1 == M2 - False\n",
    "            # H1: M1 != M2 - True\n",
    "        else:\n",
    "            # Heterogeneous\n",
    "            ttest = stats.ttest_ind(groupA, groupB, equal_var=False)[1]\n",
    "            # H0: M1 == M2 - False\n",
    "            # H1: M1 != M2 - True\n",
    "    else:\n",
    "        # Non-Parametric Test\n",
    "        ttest = stats.mannwhitneyu(groupA, groupB)[1] \n",
    "        # H0: M1 == M2 - False\n",
    "        # H1: M1 != M2 - True\n",
    "        \n",
    "    # Result\n",
    "    temp = pd.DataFrame({\n",
    "        \"AB Hypothesis\":[ttest < 0.05], \n",
    "        \"p-value\":[ttest]\n",
    "    })\n",
    "    temp[\"Test Type\"] = np.where((ntA == False) & (ntB == False), \"Parametric\", \"Non-Parametric\")\n",
    "    temp[\"AB Hypothesis\"] = np.where(temp[\"AB Hypothesis\"] == False, \"Fail to Reject H0\", \"Reject H0\")\n",
    "    temp[\"Comment\"] = np.where(temp[\"AB Hypothesis\"] == \"Fail to Reject H0\", \"A/B groups are similar!\", \"A/B groups are not similar!\")\n",
    "    \n",
    "    # Columns\n",
    "    if (ntA == False) & (ntB == False):\n",
    "        temp[\"Homogeneity\"] = np.where(leveneTest == False, \"Yes\", \"No\")\n",
    "        temp = temp[[\"Test Type\", \"Homogeneity\",\"AB Hypothesis\", \"p-value\", \"Comment\"]]\n",
    "    else:\n",
    "        temp = temp[[\"Test Type\",\"AB Hypothesis\", \"p-value\", \"Comment\"]]\n",
    "    \n",
    "    # Print Hypothesis\n",
    "    print(\"# A/B Testing Hypothesis\")\n",
    "    print(\"H0: A == B\")\n",
    "    print(\"H1: A != B\", \"\\n\")\n",
    "    \n",
    "    return temp\n",
    "    \n",
    "    \n",
    "    \n",
    "# Apply A/B Testing\n",
    "# AB_Test(dataframe=ab, group = \"version\", target = \"sum_gamerounds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813afeb",
   "metadata": {
    "papermill": {
     "duration": 0.011024,
     "end_time": "2023-03-28T21:09:46.685186",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.674162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A/B Testing iki örneklem oran testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1af371a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:46.709981Z",
     "iopub.status.busy": "2023-03-28T21:09:46.709037Z",
     "iopub.status.idle": "2023-03-28T21:09:47.480605Z",
     "shell.execute_reply": "2023-03-28T21:09:47.479322Z"
    },
    "papermill": {
     "duration": 0.787452,
     "end_time": "2023-03-28T21:09:47.483778",
     "exception": false,
     "start_time": "2023-03-28T21:09:46.696326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "# df = sns.load_dataset(\"titanic\")\n",
    "# df.head()\n",
    "\n",
    "# df.loc[df[\"sex\"] == \"female\", \"survived\"].mean()\n",
    "\n",
    "# df.loc[df[\"sex\"] == \"male\", \"survived\"].mean()\n",
    "\n",
    "# female_succ_count = df.loc[df[\"sex\"] == \"female\", \"survived\"].sum()\n",
    "# male_succ_count = df.loc[df[\"sex\"] == \"male\", \"survived\"].sum()\n",
    "\n",
    "# test_stat, pvalue = proportions_ztest(count=[female_succ_count, male_succ_count],\n",
    "#                                       nobs=[df.loc[df[\"sex\"] == \"female\", \"survived\"].shape[0],\n",
    "#                                             df.loc[df[\"sex\"] == \"male\", \"survived\"].shape[0]])\n",
    "# print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d3572",
   "metadata": {
    "papermill": {
     "duration": 0.010899,
     "end_time": "2023-03-28T21:09:47.506045",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.495146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ANOVA\n",
    "Aşağıdaki cellin hepsi seçilerek comment out yaptıktan sonra kodlar incelenebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d8788ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:47.531110Z",
     "iopub.status.busy": "2023-03-28T21:09:47.530220Z",
     "iopub.status.idle": "2023-03-28T21:09:47.536914Z",
     "shell.execute_reply": "2023-03-28T21:09:47.535993Z"
    },
    "papermill": {
     "duration": 0.022113,
     "end_time": "2023-03-28T21:09:47.539503",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.517390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # 1. Hipotezleri kur\n",
    "\n",
    "# # HO: m1 = m2 = m3 = m4\n",
    "# # Grup ortalamaları arasında fark yoktur.\n",
    "\n",
    "# # H1: .. fark vardır\n",
    "\n",
    "# # 2. Varsayım kontrolü\n",
    "\n",
    "# # Normallik varsayımı\n",
    "# # Varyans homojenliği varsayımı\n",
    "\n",
    "# # Varsayım sağlanıyorsa one way anova\n",
    "# # Varsayım sağlanmıyorsa kruskal\n",
    "\n",
    "# # H0: Normal dağılım varsayımı sağlanmaktadır.\n",
    "\n",
    "# for group in list(df[\"day\"].unique()):\n",
    "#     pvalue = shapiro(df.loc[df[\"day\"] == group, \"total_bill\"])[1]\n",
    "#     print(group, 'p-value: %.4f' % pvalue)\n",
    "# ##### burada herhangi ikiliden biri sağlansaydı ne olacaktı?\n",
    "# # test_stat, pvalue = shapiro(df.loc[df[\"Outcome\"] == 0, \"Age\"].dropna())\n",
    "# # H0: Varyans homojenliği varsayımı sağlanmaktadır.\n",
    "\n",
    "# test_stat, pvalue = levene(df.loc[df[\"day\"] == \"Sun\", \"total_bill\"],\n",
    "#                            df.loc[df[\"day\"] == \"Sat\", \"total_bill\"],\n",
    "#                            df.loc[df[\"day\"] == \"Thur\", \"total_bill\"],\n",
    "#                            df.loc[df[\"day\"] == \"Fri\", \"total_bill\"])\n",
    "# print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n",
    "\n",
    "\n",
    "# # 3. Hipotez testi ve p-value yorumu\n",
    "\n",
    "# # Hiç biri sağlamıyor.\n",
    "# df.groupby(\"day\").agg({\"total_bill\": [\"mean\", \"median\"]})\n",
    "\n",
    "\n",
    "# # HO: Grup ortalamaları arasında ist ol anl fark yoktur\n",
    "\n",
    "# # parametrik anova testi: #bunların alfa değeri nedir\n",
    "# f_oneway(df.loc[df[\"day\"] == \"Thur\", \"total_bill\"],\n",
    "#          df.loc[df[\"day\"] == \"Fri\", \"total_bill\"],\n",
    "#          df.loc[df[\"day\"] == \"Sat\", \"total_bill\"],\n",
    "#          df.loc[df[\"day\"] == \"Sun\", \"total_bill\"])\n",
    "\n",
    "# # Nonparametrik anova testi:\n",
    "# kruskal(df.loc[df[\"day\"] == \"Thur\", \"total_bill\"],\n",
    "#         df.loc[df[\"day\"] == \"Fri\", \"total_bill\"],\n",
    "#         df.loc[df[\"day\"] == \"Sat\", \"total_bill\"],\n",
    "#         df.loc[df[\"day\"] == \"Sun\", \"total_bill\"])\n",
    "\n",
    "# from statsmodels.stats.multicomp import MultiComparison\n",
    "# comparison = MultiComparison(df['total_bill'], df['day'])\n",
    "# tukey = comparison.tukeyhsd(0.05)\n",
    "# print(tukey.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b4b2c",
   "metadata": {
    "papermill": {
     "duration": 0.010937,
     "end_time": "2023-03-28T21:09:47.561728",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.550791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Association Rule Learning Apriori\n",
    "\n",
    "* 1. Veri Ön İşleme\n",
    "* 2. ARL Veri Yapısını Hazırlama (Invoice-Product Matrix)\n",
    "* 3. Birliktelik Kurallarının Çıkarılması\n",
    "* 4. Çalışmanın Scriptini Hazırlama\n",
    "* 5. Sepet Aşamasındaki Kullanıcılara Ürün Önerisinde Bulunmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75d22dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:47.586860Z",
     "iopub.status.busy": "2023-03-28T21:09:47.586052Z",
     "iopub.status.idle": "2023-03-28T21:09:47.602192Z",
     "shell.execute_reply": "2023-03-28T21:09:47.601091Z"
    },
    "papermill": {
     "duration": 0.031447,
     "end_time": "2023-03-28T21:09:47.604726",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.573279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def outlier_thresholds(dataframe, variable):\n",
    "    quartile1 = dataframe[variable].quantile(0.01)\n",
    "    quartile3 = dataframe[variable].quantile(0.99)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "def retail_data_prep(dataframe):\n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n",
    "    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n",
    "    dataframe = dataframe[dataframe[\"Price\"] > 0]\n",
    "    replace_with_thresholds(dataframe, \"Quantity\")\n",
    "    replace_with_thresholds(dataframe, \"Price\")\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def create_invoice_product_df(dataframe, id=False):\n",
    "    if id:\n",
    "        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n",
    "            applymap(lambda x: 1 if x > 0 else 0)\n",
    "    else:\n",
    "        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n",
    "            applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "def check_id(dataframe, stock_code):\n",
    "    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n",
    "    print(product_name)\n",
    "\n",
    "\n",
    "def create_rules(dataframe, id=True, country=\"France\"):\n",
    "    dataframe = dataframe[dataframe['Country'] == country]\n",
    "    dataframe = create_invoice_product_df(dataframe, id)\n",
    "    frequent_itemsets = apriori(dataframe, min_support=0.01, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\n",
    "    return rules\n",
    "def arl_recommender(rules_df, product_id, rec_count=1):\n",
    "    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n",
    "    recommendation_list = []\n",
    "    for i, product in enumerate(sorted_rules[\"antecedents\"]):\n",
    "        for j in list(product):\n",
    "            if j == product_id:\n",
    "                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"])[0])\n",
    "\n",
    "    return recommendation_list[0:rec_count]\n",
    "\n",
    "\n",
    "# arl_recommender(rules, 22492, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696420b3",
   "metadata": {
    "papermill": {
     "duration": 0.011199,
     "end_time": "2023-03-28T21:09:47.627264",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.616065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Content Based Recommendation\n",
    "*  1. TF-IDF Matrisinin Oluşturulması\n",
    "* 2. Cosine Similarity Matrisinin Oluşturulması\n",
    "* 3. Benzerliklere Göre Önerilerin Yapılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e65b53a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:47.652238Z",
     "iopub.status.busy": "2023-03-28T21:09:47.651535Z",
     "iopub.status.idle": "2023-03-28T21:09:47.839276Z",
     "shell.execute_reply": "2023-03-28T21:09:47.837969Z"
    },
    "papermill": {
     "duration": 0.203629,
     "end_time": "2023-03-28T21:09:47.842187",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.638558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_sim(dataframe):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    dataframe['overview'] = dataframe['overview'].fillna('')\n",
    "    tfidf_matrix = tfidf.fit_transform(dataframe['overview'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim\n",
    "def content_based_recommender(title, cosine_sim, dataframe):\n",
    "    # index'leri olusturma\n",
    "    indices = pd.Series(dataframe.index, index=dataframe['title'])\n",
    "    indices = indices[~indices.index.duplicated(keep='last')]\n",
    "    # title'ın index'ini yakalama\n",
    "    movie_index = indices[title]\n",
    "    # title'a gore benzerlik skorlarını hesapalama\n",
    "    similarity_scores = pd.DataFrame(cosine_sim[movie_index], columns=[\"score\"])\n",
    "    # kendisi haric ilk 10 filmi getirme\n",
    "    movie_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:11].index\n",
    "    return dataframe['title'].iloc[movie_indices]\n",
    "\n",
    "# cosine_sim = calculate_cosine_sim(df)\n",
    "# content_based_recommender('The Dark Knight Rises', cosine_sim, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b879362",
   "metadata": {
    "papermill": {
     "duration": 0.010722,
     "end_time": "2023-03-28T21:09:47.864442",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.853720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Item-Based Collaborative Filtering\n",
    "\n",
    "* Adım 1: Veri Setinin Hazırlanması\n",
    "* Adım 2: User Movie Df'inin Oluşturulması\n",
    "* Adım 3: Item-Based Film Önerilerinin Yapılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a033ea31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:47.888544Z",
     "iopub.status.busy": "2023-03-28T21:09:47.888113Z",
     "iopub.status.idle": "2023-03-28T21:09:47.897910Z",
     "shell.execute_reply": "2023-03-28T21:09:47.896778Z"
    },
    "papermill": {
     "duration": 0.024845,
     "end_time": "2023-03-28T21:09:47.900326",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.875481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_user_movie_df():\n",
    "    import pandas as pd\n",
    "    movie = pd.read_csv('datasets/movie_lens_dataset/movie.csv')\n",
    "    rating = pd.read_csv('datasets/movie_lens_dataset/rating.csv')\n",
    "    df = movie.merge(rating, how=\"left\", on=\"movieId\")\n",
    "    comment_counts = pd.DataFrame(df[\"title\"].value_counts())\n",
    "    rare_movies = comment_counts[comment_counts[\"title\"] <= 1000].index\n",
    "    common_movies = df[~df[\"title\"].isin(rare_movies)]\n",
    "    user_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n",
    "    return user_movie_df\n",
    "def item_based_recommender(movie_name, user_movie_df):\n",
    "    movie_name = user_movie_df[movie_name]\n",
    "    return user_movie_df.corrwith(movie_name).sort_values(ascending=False).head(10)\n",
    "def check_film(keyword, user_movie_df):\n",
    "    return [col for col in user_movie_df.columns if keyword in col]\n",
    "\n",
    "\n",
    "# user_movie_df = create_user_movie_df()\n",
    "# item_based_recommender(\"Matrix, The (1999)\", user_movie_df)\n",
    "# movie_name = pd.Series(user_movie_df.columns).sample(1).values[0]\n",
    "# item_based_recommender(movie_name, user_movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8cec5a",
   "metadata": {
    "papermill": {
     "duration": 0.010771,
     "end_time": "2023-03-28T21:09:47.922474",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.911703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# User-Based Collaborative Filtering\n",
    "* Adım 1: Veri Setinin Hazırlanması\n",
    "* Adım 2: Öneri Yapılacak Kullanıcının İzlediği Filmlerin Belirlenmesi\n",
    "* Adım 3: Aynı Filmleri İzleyen Diğer Kullanıcıların Verisine ve Id'lerine Erişmek\n",
    "* Adım 4: Öneri Yapılacak Kullanıcı ile En Benzer Davranışlı Kullanıcıların Belirlenmesi\n",
    "* Adım 5: Weighted Average Recommendation Score'un Hesaplanması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c29d2e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:47.946559Z",
     "iopub.status.busy": "2023-03-28T21:09:47.946104Z",
     "iopub.status.idle": "2023-03-28T21:09:47.959274Z",
     "shell.execute_reply": "2023-03-28T21:09:47.958074Z"
    },
    "papermill": {
     "duration": 0.028205,
     "end_time": "2023-03-28T21:09:47.961706",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.933501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def user_based_recommender(random_user, user_movie_df, ratio=60, cor_th=0.65, score=3.5):\n",
    "    import pandas as pd\n",
    "    random_user_df = user_movie_df[user_movie_df.index == random_user]\n",
    "    movies_watched = random_user_df.columns[random_user_df.notna().any()].tolist()\n",
    "    movies_watched_df = user_movie_df[movies_watched]\n",
    "    user_movie_count = movies_watched_df.T.notnull().sum()\n",
    "    user_movie_count = user_movie_count.reset_index()\n",
    "    user_movie_count.columns = [\"userId\", \"movie_count\"]\n",
    "    perc = len(movies_watched) * ratio / 100\n",
    "    users_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > perc][\"userId\"]\n",
    "\n",
    "    final_df = pd.concat([movies_watched_df[movies_watched_df.index.isin(users_same_movies)],\n",
    "                          random_user_df[movies_watched]])\n",
    "\n",
    "    corr_df = final_df.T.corr().unstack().sort_values().drop_duplicates()\n",
    "    corr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\n",
    "    corr_df.index.names = ['user_id_1', 'user_id_2']\n",
    "    corr_df = corr_df.reset_index()\n",
    "\n",
    "    top_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= cor_th)][\n",
    "        [\"user_id_2\", \"corr\"]].reset_index(drop=True)\n",
    "\n",
    "    top_users = top_users.sort_values(by='corr', ascending=False)\n",
    "    top_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)\n",
    "    rating = pd.read_csv('datasets/movie_lens_dataset/rating.csv')\n",
    "    top_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\n",
    "    top_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\n",
    "\n",
    "    recommendation_df = top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\n",
    "    recommendation_df = recommendation_df.reset_index()\n",
    "\n",
    "    movies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > score].sort_values(\"weighted_rating\", ascending=False)\n",
    "    movie = pd.read_csv('datasets/movie_lens_dataset/movie.csv')\n",
    "    return movies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]])\n",
    "\n",
    "\n",
    "\n",
    "# random_user = int(pd.Series(user_movie_df.index).sample(1).values)\n",
    "# user_based_recommender(random_user, user_movie_df, cor_th=0.70, score=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c373dc",
   "metadata": {
    "papermill": {
     "duration": 0.010751,
     "end_time": "2023-03-28T21:09:47.983514",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.972763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model-Based Collaborative Filtering: Matrix Factorization\n",
    "\n",
    "* Adım 1: Veri Setinin Hazırlanması\n",
    "* Adım 2: Modelleme\n",
    "* Adım 3: Model Tuning\n",
    "* Adım 4: Final Model ve Tahmin\n",
    "\n",
    "Aşağıdaki kodu okumak için önce tüm hücrenin \"comment out\"unu kaldırın"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94d62553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T21:09:48.007631Z",
     "iopub.status.busy": "2023-03-28T21:09:48.007179Z",
     "iopub.status.idle": "2023-03-28T21:09:48.014477Z",
     "shell.execute_reply": "2023-03-28T21:09:48.013239Z"
    },
    "papermill": {
     "duration": 0.022251,
     "end_time": "2023-03-28T21:09:48.016752",
     "exception": false,
     "start_time": "2023-03-28T21:09:47.994501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from surprise.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "# from surprise import Reader, SVD, Dataset, accuracy\n",
    "\n",
    "\n",
    "# movie = pd.read_csv('datasets/movie_lens_dataset/movie.csv')\n",
    "# rating = pd.read_csv('datasets/movie_lens_dataset/rating.csv')\n",
    "# df = movie.merge(rating, how=\"left\", on=\"movieId\")\n",
    "# df.head()\n",
    "# movie.head()\n",
    "# rating.head()\n",
    "# movie_ids = [130219, 356, 4422, 541]\n",
    "# movies = [\"The Dark Knight (2011)\",\n",
    "#           \"Cries and Whispers (Viskningar och rop) (1972)\",\n",
    "#           \"Forrest Gump (1994)\",\n",
    "#           \"Blade Runner (1982)\"]\n",
    "\n",
    "# sample_df = df[df.movieId.isin(movie_ids)]\n",
    "# sample_df.head()\n",
    "\n",
    "# sample_df.shape\n",
    "\n",
    "# user_movie_df = sample_df.pivot_table(index=[\"userId\"],\n",
    "#                                       columns=[\"title\"],\n",
    "#                                       values=\"rating\")\n",
    "\n",
    "# user_movie_df.shape\n",
    "\n",
    "# reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# data = Dataset.load_from_df(sample_df[['userId',\n",
    "#                                        'movieId',\n",
    "#                                        'rating']], reader)\n",
    "\n",
    "# ##############################\n",
    "# # Adım 2: Modelleme\n",
    "# ##############################\n",
    "\n",
    "# trainset, testset = train_test_split(data, test_size=.25)\n",
    "# svd_model = SVD()\n",
    "# svd_model.fit(trainset)\n",
    "# predictions = svd_model.test(testset)\n",
    "\n",
    "# accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "# svd_model.predict(uid=1.0, iid=541, verbose=True)\n",
    "\n",
    "# svd_model.predict(uid=1.0, iid=356, verbose=True)\n",
    "\n",
    "\n",
    "# sample_df[sample_df[\"userId\"] == 1]\n",
    "\n",
    "# ##############################\n",
    "# # Adım 3: Model Tuning\n",
    "# ##############################\n",
    "\n",
    "# param_grid = {'n_epochs': [5, 10, 20],\n",
    "#               'lr_all': [0.002, 0.005, 0.007]}\n",
    "\n",
    "\n",
    "# gs = GridSearchCV(SVD,\n",
    "#                   param_grid,\n",
    "#                   measures=['rmse', 'mae'],\n",
    "#                   cv=3,\n",
    "#                   n_jobs=-1,\n",
    "#                   joblib_verbose=True)\n",
    "\n",
    "# gs.fit(data)\n",
    "\n",
    "# gs.best_score['rmse']\n",
    "# gs.best_params['rmse']\n",
    "\n",
    "\n",
    "# ##############################\n",
    "# # Adım 4: Final Model ve Tahmin\n",
    "# ##############################\n",
    "\n",
    "# dir(svd_model)\n",
    "# svd_model.n_epochs\n",
    "\n",
    "# svd_model = SVD(**gs.best_params['rmse'])\n",
    "\n",
    "# data = data.build_full_trainset()\n",
    "# svd_model.fit(data)\n",
    "\n",
    "# svd_model.predict(uid=1.0, iid=541, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.772873,
   "end_time": "2023-03-28T21:09:48.750198",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-28T21:09:35.977325",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
